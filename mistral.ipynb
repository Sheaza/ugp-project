{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('emotion')\n",
    "\n",
    "label_mapping = {\n",
    "    0: \"sadness\",\n",
    "    1: \"joy\",\n",
    "    2: \"love\",\n",
    "    3: \"anger\",\n",
    "    4: \"fear\",\n",
    "    5: \"surprise\",\n",
    "}\n",
    "emotions = [\"sadness\", \"joy\",\"love\",\"anger\",\"fear\", \"surprise\"]\n",
    "test_dataset = dataset['validation']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-31T15:27:24.099222100Z",
     "start_time": "2025-01-31T15:26:44.581906500Z"
    }
   },
   "id": "1870fc3b4f8e75d0"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def get_llm_response(prompt):\n",
    "    response = ollama.generate(model='mistral', prompt=prompt)\n",
    "    return response['response'].strip()\n",
    "\n",
    "def classify_emotion(text):\n",
    "    prompt = f\"Classify the emotion in the following sentence with only one word. The emotion has to be one of the following: {', '.join(emotions)}. Don't explain your choice.\\nSentence: '{text}'\\nEmotion:\"\n",
    "    return get_llm_response(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-31T15:57:17.176607700Z",
     "start_time": "2025-01-31T15:57:17.170100100Z"
    }
   },
   "id": "174b724284e0e6ca"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:28<00:00,  7.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = len(test_dataset)\n",
    "\n",
    "sample_responses = []\n",
    "\n",
    "for example in tqdm.tqdm(test_dataset):\n",
    "\n",
    "    text = example['text']\n",
    "    expected_label = label_mapping[example['label']]\n",
    " \n",
    "    predicted_label = classify_emotion(text)\n",
    "    \n",
    "\n",
    "    if expected_label.lower() in predicted_label.lower() :\n",
    "        correct += 1\n",
    "    \n",
    "    sample_responses.append({\n",
    "        \"text\": text,\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"expected_label\": expected_label,\n",
    "    })\n",
    "\n",
    "accuracy = correct / total * 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-31T16:01:46.098622700Z",
     "start_time": "2025-01-31T15:57:17.409470100Z"
    }
   },
   "id": "c919337a307277ba"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy modelu: 40.35%\n",
      "\n",
      "Przykładowe odpowiedzi modelu:\n",
      "Tekst: im feeling quite sad and sorry for myself but ill snap out of it soon\n",
      "Odpowiedź modelu: Sadness\n",
      "Oczekiwane: sadness\n",
      "Tekst: i feel like i am still looking at a blank canvas blank pieces of paper\n",
      "Odpowiedź modelu: Sadness\n",
      "Oczekiwane: sadness\n",
      "Tekst: i feel like a faithful servant\n",
      "Odpowiedź modelu: Loyalty (not one of the specified emotions, but often associated with a sense of duty or commitment)\n",
      "Oczekiwane: love\n",
      "Tekst: i am just feeling cranky and blue\n",
      "Odpowiedź modelu: Sadness\n",
      "Oczekiwane: anger\n",
      "Tekst: i can have for a treat or if i am feeling festive\n",
      "Odpowiedź modelu: Joy\n",
      "Oczekiwane: joy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Accuracy modelu: {accuracy:.2f}%\")\n",
    "print(\"\\nPrzykładowe odpowiedzi modelu:\")\n",
    "for response in sample_responses[:5]:\n",
    "    print(f\"Tekst: {response['text']}\")\n",
    "    print(f\"Odpowiedź modelu: {response['predicted_label']}\")\n",
    "    print(f\"Oczekiwane: {response['expected_label']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-31T16:05:04.432748800Z",
     "start_time": "2025-01-31T16:05:04.420971800Z"
    }
   },
   "id": "fc4116a3ed062de1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podsumowując: Wynik ogólnie jest dość niski dla Mistrala i widać, że ma problemy ze zrozumieniem polecenia dokładnie. Ale problem jest też w sumie z danymi, nie dziwie się, że model nie radzi sobie bez żadnego treningu, bo zdania są na tyle specyficzne, że sam miałbym problem je sklasyfikować."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f376ab90d43d0ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
